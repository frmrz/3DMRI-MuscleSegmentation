{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install monai","metadata":{"id":"FYEpx2W8M7pP","execution":{"iopub.status.busy":"2023-02-12T07:38:28.980961Z","iopub.execute_input":"2023-02-12T07:38:28.981388Z","iopub.status.idle":"2023-02-12T07:38:43.700804Z","shell.execute_reply.started":"2023-02-12T07:38:28.981359Z","shell.execute_reply":"2023-02-12T07:38:43.699539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install 'monai[nibabel, skimage, pillow, tensorboard, gdown, ignite, torchvision, itk, tqdm, lmdb, psutil, cucim, openslide, pandas, einops, transformers, mlflow, matplotlib, tensorboardX, tifffile, imagecodecs, pyyaml, fire, jsonschema, pynrrd, pydicom, h5py]'\n","metadata":{"execution":{"iopub.status.busy":"2023-02-11T19:21:12.240995Z","iopub.execute_input":"2023-02-11T19:21:12.241367Z","iopub.status.idle":"2023-02-11T19:22:15.949615Z","shell.execute_reply.started":"2023-02-11T19:21:12.241334Z","shell.execute_reply":"2023-02-11T19:22:15.948341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import logging\nimport os\nimport shutil\nimport sys\nimport tempfile\nfrom glob import glob\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom tqdm import tqdm\nimport time\n\nimport torch\nfrom PIL import Image\nfrom torch.utils.tensorboard import SummaryWriter\n\n\nimport monai\nfrom monai.data import CacheDataset, Dataset, decollate_batch, DataLoader\nfrom monai.inferers import sliding_window_inference\nfrom monai.metrics import DiceMetric\nfrom monai.transforms import (\n    Activations,\n    AsDiscrete,\n    AddChanneld,\n    Compose,\n    CropForegroundd,\n    LoadImaged,\n    Orientationd,\n    Resized,\n    EnsureChannelFirstd,\n    RandFlipd,\n    RandCropByPosNegLabeld,\n    RandShiftIntensityd,\n    ScaleIntensityRanged,\n    DataStats,\n    Spacingd,\n    AsDiscreted,\n    LabelToMaskd,\n    RandRotate90d,\n    EnsureType,\n    SaveImaged,\n    Invertd,\n    EnsureTyped,\n    ToTensord,\n    RandAffined,\n    EnsureTyped,\n    CenterSpatialCropd    \n\n)\nfrom monai.utils import first, set_determinism\nfrom monai.losses import DiceLoss,DiceCELoss\nfrom monai.networks.nets import UNet, UNETR, SwinUNETR\nfrom monai.networks.layers import Norm\n\n#%%\n\"\"\"Set determinism per un training ripetibile\"\"\"\n\nSEED = 33 \nset_determinism(SEED)\n\n\"\"\"Dictionaries\"\"\"\n#%%================================= CARTELLE DA CAMBIARE =====================\ndirectory= '/kaggle/input/dataset-3d-hm'\n\ntrain_IMG_path = sorted(glob(os.path.join(directory,'imagesTr-gamba','*.nii')))\ntrain_MASK_path = sorted(glob(os.path.join(directory,'labelsTr-gamba','*.nii')))\n\n\nval_IMG_path = sorted(glob(os.path.join(directory,'imagesVl-gamba','*.nii')))\nval_MASK_path = sorted(glob(os.path.join(directory,'labelsVl-gamba','*.nii')))\n\n#estrarre i path di immagini e maschere manuali del test set\n#test_IMG_path = sorted(glob(os.path.join(directory,'imagesTs-gamba','*.nii')))\n#test_MASK_path = sorted(glob(os.path.join(directory,'labelsTs-gamba','*.nii')))","metadata":{"id":"FYEpx2W8M7pP","execution":{"iopub.status.busy":"2023-02-11T19:22:15.951868Z","iopub.execute_input":"2023-02-11T19:22:15.952491Z","iopub.status.idle":"2023-02-11T19:22:22.781531Z","shell.execute_reply.started":"2023-02-11T19:22:15.952445Z","shell.execute_reply":"2023-02-11T19:22:22.780304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_dir = '/kaggle/working/'\n\nif not os.path.exists(model_dir):\n  os.mkdir(model_dir)\n#%%\n\ntrain_files = [{\"image\": image_name, \"label\": mask_name} for image_name,mask_name in zip(train_IMG_path,train_MASK_path)]\nval_files = [{\"image\": image_name, \"label\": mask_name} for image_name,mask_name in zip(val_IMG_path,val_MASK_path)]\n#test_files = [{\"image\": image_name, \"label\": mask_name} for image_name,mask_name in zip(test_IMG_path,test_MASK_path)]\n\n\"\"\"Pre-processing\"\"\"\n\n#trasformazione del training\ntrain_transforms = Compose(\n    [\n        LoadImaged(keys=[\"image\", \"label\"]),\n        EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n        CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n        Spacingd(keys=[\"image\", \"label\"], pixdim=(\n              1,1,5.0), mode=(\"bilinear\", \"nearest\")),\n        RandCropByPosNegLabeld(\n            keys=[\"image\", \"label\"],\n            label_key=\"label\",\n            spatial_size=(96,96,32),\n            pos=1,\n            neg=1,\n            num_samples=4,\n            image_key=\"image\",\n            image_threshold=0,\n        ),\n        RandFlipd(\n            keys=[\"image\", \"label\"],\n            spatial_axis=[0],\n            prob=0.10,\n        ),\n        RandFlipd(\n            keys=[\"image\", \"label\"],\n            spatial_axis=[1],\n            prob=0.10,\n        ),\n        RandFlipd(\n            keys=[\"image\", \"label\"],\n            spatial_axis=[2],\n            prob=0.10,\n        ),\n        RandRotate90d(\n            keys=[\"image\", \"label\"],\n            prob=0.10,\n            max_k=3,\n        ),\n        RandShiftIntensityd(\n            keys=[\"image\"],\n            offsets=0.10,\n            prob=0.50,\n        ),\n    ] )      \n\n\n#trasformazioni del validation\nval_transforms = Compose(\n    [\n        LoadImaged(keys=[\"image\", \"label\"]),\n        EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n        CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n        Spacingd(keys=[\"image\", \"label\"], pixdim=(\n            1,1,5.0), mode=(\"bilinear\", \"nearest\"))\n       \n        \n    \n    ]\n)\n\n\"\"\"Applicare le trasformazioni\"\"\"\n\ntrain_ds = Dataset(train_files , train_transforms)\n#train_loader = DataLoader( train_ds, batch_size=1)\ntrain_loader = DataLoader( train_ds, batch_size=2, shuffle=True, num_workers=4)\n\nval_ds = Dataset(val_files , val_transforms)\nval_loader = DataLoader( val_ds, batch_size=1)\n\n\"\"\"Visualizzare un esempio \"\"\"\n\n# train_patient = first(train_loader)\n\n# print(train_patient[\"image\"].shape,train_patient[\"label\"].shape)\n\n# slice_n = 15\n\n# plt.figure('prova',(12,6))\n\n\n# plt.subplot(1,2,1)\n# plt.title('FILE TRASFORMATO')\n# plt.imshow(train_patient[\"image\"][0,0,:,:,slice_n],cmap='gray')\n\n# plt.subplot(1,2,2)\n# plt.title('Segmentazione')\n# plt.imshow(train_patient[\"label\"][0,0,:,:,slice_n])\n\n# plt.show()\n#%% creare il modello\ntrain_patient = first(train_loader)\n\nprint(train_patient[\"image\"].shape,train_patient[\"label\"].shape)\n\nslice_n = 15\n\nplt.figure('prova',(12,6))\n\n\nplt.subplot(1,2,1)\nplt.title('FILE TRASFORMATO')\nplt.imshow(train_patient[\"image\"][0,0,:,:,slice_n],cmap='gray')\n\nplt.subplot(1,2,2)\nplt.title('Segmentazione')\nplt.imshow(train_patient[\"label\"][0,0,:,:,slice_n])\n\nplt.show()\n","metadata":{"id":"4S7ehdGZNkar","execution":{"iopub.status.busy":"2023-02-11T19:22:22.784584Z","iopub.execute_input":"2023-02-11T19:22:22.785039Z","iopub.status.idle":"2023-02-11T19:22:29.699019Z","shell.execute_reply.started":"2023-02-11T19:22:22.784999Z","shell.execute_reply":"2023-02-11T19:22:29.697941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\"\"\"Creazione della cartella in cui salvare il modello , se non esiste già\n\n\"\"\"\n\n\n\"\"\"\n* Model\n* Optimizer\n* Loss function\n* Dice metric\n\n\"\"\"\n\nos.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \nmodel = SwinUNETR(\n    img_size=(96,96, 32),   \n    in_channels=1,\n    out_channels=10,\n    feature_size=24,\n    use_checkpoint=True,\n).to(device)\nmodel_type = 'SwinUNETR'\n\n#model = UNet(\n#     spatial_dims=3,\n#     in_channels=1,\n#     out_channels=10,\n#     channels=(16, 32, 64, 128, 256),\n#     strides=(2, 2, 2, 2),\n#     num_res_units=2,\n#     norm=Norm.BATCH,\n# ).to(device)\n#model_type = 'UNet'\n\n#model.load_state_dict(torch.load(\n #    os.path.join(model_dir, \"best_metric_model_SwinUNETR_coscia.pth\")))\n\nloss_function = DiceCELoss(to_onehot_y=True, softmax=True)    #softmax è per quella multiclasse. segmentazione binaria è meglio sigmoid\ntorch.backends.cudnn.benchmark = True\noptimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5)\ndice_metric = DiceMetric(include_background=True, reduction=\"mean\", get_not_nans=False)\n\n#%%\n\n\"\"\"Standard Pytorch training\"\"\"\n\nmax_epochs = 300\nval_interval = 1\nbest_metric = -1\nbest_metric_epoch = -1\nepoch_loss_values = []\nmetric_values = []\nepoch_times = []\ntotal_start = time.time()\npost_pred = Compose([Activations(softmax=True),AsDiscrete(argmax=True, to_onehot=10)])\npost_label = Compose([AsDiscrete(to_onehot=10)])\n\nfor epoch in range(max_epochs):\n    epoch_start = time.time()\n    print(\"-\" * 10)\n    print(f\"epoch {epoch + 1}/{max_epochs}\")\n    model.train()\n    epoch_loss = 0\n    step = 0\n    for batch_data in train_loader:\n        step_start = time.time()\n        step += 1\n        inputs, labels = (\n            batch_data[\"image\"].to(device),\n            batch_data[\"label\"].to(device),\n        )\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = loss_function(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        epoch_loss += loss.item()\n        print(\n            f\"{step}/{len(train_ds) // train_loader.batch_size}, \"\n            f\"train_loss: {loss.item():.4f}\")\n    epoch_loss /= step\n    epoch_loss_values.append(epoch_loss)\n    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n\n    if (epoch + 1) % val_interval == 0:\n        model.eval()\n        with torch.no_grad():\n            for val_data in val_loader:     \n                val_inputs, val_labels = (\n                    val_data[\"image\"].to(device),\n                    val_data[\"label\"].to(device),\n                )\n                roi_size = (96,96,32)  \n                sw_batch_size = 2\n                val_outputs = sliding_window_inference(\n                    val_inputs, roi_size, sw_batch_size, model)\n                val_outputs = [post_pred(i) for i in decollate_batch(val_outputs)]\n                val_labels = [post_label(i) for i in decollate_batch(val_labels)]\n               \n                # compute metric for current iteration\n                dice_metric(y_pred=val_outputs, y=val_labels)\n\n\n            # aggregate the final mean dice result\n            metric = dice_metric.aggregate().item()\n            # reset the status for next validation round\n            dice_metric.reset()\n\n            metric_values.append(metric)\n            if metric > best_metric:\n                best_metric = metric\n                best_metric_epoch = epoch + 1\n                torch.save(model.state_dict(), os.path.join(\n                    model_dir, \"best_metric_model_SwinUNETR_gamba_aiuto.pth\"))\n                print(\"saved new best metric model\")\n            print(\n                f\"current epoch: {epoch + 1} current mean dice: {metric:.4f}\"\n                f\"\\nbest mean dice: {best_metric:.4f} \"\n                f\"at epoch: {best_metric_epoch}\"\n            )\n            ","metadata":{"id":"ilYNxVw9Nir8","execution":{"iopub.status.busy":"2023-02-11T19:22:29.701642Z","iopub.execute_input":"2023-02-11T19:22:29.702081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n#%%   VISUALIZZAZIONE\n\n\"\"\"Visualizzazione Loss e Metrics\"\"\"\n\nprint(\n    f\"train completed, best_metric: {best_metric:.4f} \"\n    f\"at epoch: {best_metric_epoch}\"\n    f\"model type: {model_type}\"\n    f\" total time: {(time.time() - total_start):.4f}\")\n\n\n\nplt.figure(\"train\", (12, 6))\nplt.subplot(1, 2, 1)\nplt.title(\"Epoch Average Loss\")\nx = [i + 1 for i in range(len(epoch_loss_values))]\ny = epoch_loss_values\nplt.xlabel(\"epoch\")\nplt.plot(x, y)\nplt.subplot(1, 2, 2)\nplt.title(\"Val Mean Dice\")\nx = [val_interval * (i + 1) for i in range(len(metric_values))]\ny = metric_values\nplt.xlabel(\"epoch\")\nplt.plot(x, y)\nplt.show()\n\n","metadata":{"id":"zrDKti_MLphx","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nmodel_dir = '/kaggle/working/MODEL-COSCIA'\nworking_dir = '/kaggle/working/'\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") #\nmodel = SwinUNETR(\n    img_size=(96,96, 32),   \n    in_channels=1,\n    out_channels=13,\n    feature_size=24,\n    use_checkpoint=True,\n).to(device)\n\nmodel.load_state_dict(torch.load(\n     os.path.join(working_dir, \"best_metric_model_SwinUNETR_gamba_aiuto.pth\")))\ntorch.save(model.state_dict(), os.path.join(\n                    working_dir, \"best_metric_model_SwinUNETR_gamba_aiuto.pth\"))\n","metadata":{},"execution_count":null,"outputs":[]}]}